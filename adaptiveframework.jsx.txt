import { Card, CardContent } from "@/components/ui/card";
import { Button } from "@/components/ui/button";
import { motion } from "framer-motion";
import { useState } from "react";

export default function AdaptiveAIFramework() {
  const [selectedSection, setSelectedSection] = useState(null);

  const sections = [
    {
      title: "Lifecycle Stages",
      items: [
        "Problem Definition",
        "Data Collection",
        "Model Development",
        "Deployment & Integration",
        "Monitoring & Updating",
        "Decommissioning",
      ],
    },
    {
      title: "Governance Pillars",
      items: [
        "Data Ownership & Stewardship",
        "Liability & Accountability",
        "Patient Privacy & Consent",
        "Cybersecurity & Resilience",
      ],
    },
    {
      title: "Policy Recommendations",
      items: [
        "Legislative and Regulatory Reforms",
        "System Implementation Supports",
      ],
    },
  ];

  const descriptions = {
    "Problem Definition": `Co-design problem definitions with clinicians, patients, and caregivers. Map acceptable risks and benefits. 
Real World Risk: IBM Watson AI recommending unsafe cancer treatments (STAT, 2018).
Mitigation: Mandatory clinical co-design workshops and risk documentation.`,
    
    "Data Collection": `Ensure datasets are diverse, consented, and representative. Track data provenance and ownership.
Real World Risk: Racial bias in healthcare algorithms (Science, 2019).
Mitigation: Conduct equity audits, supplement gaps with synthetic data.`,

    "Model Development": `Focus on explainability, validation, and bias mitigation during model building.
Real World Risk: Google Health's AI misdiagnosed retinal images (Nature, 2020).
Mitigation: External validation on diverse cohorts before deployment.`,

    "Deployment & Integration": `Clarify liability, integrate seamlessly into clinical workflows, and document human-AI interactions.
Real World Risk: Clinical fatigue due to poor AI interface design.
Mitigation: Conduct workflow mapping and usability testing pre-launch.`,

    "Monitoring & Updating": `Mandate continuous post-deployment surveillance and model updating.
Real World Risk: Deteriorating AI model performance over time (NEJM AI, 2021).
Mitigation: Require regular revalidation and clinician feedback loops.`,

    "Decommissioning": `Have responsible sunset plans for aging AI systems.
Real World Risk: Legacy decision aids delivering outdated recommendations.
Mitigation: Enforce 'expiry dates' and formal review cycles.`,

    "Data Ownership & Stewardship": `Patients must have real-time control over their health data. Implement federated models for shared stewardship.
Reference: OECD AI Principles, WHO Data Governance Guidelines.`,

    "Liability & Accountability": `Shared responsibility between developers, clinicians, and institutions.
Reference: WHO Ethics & Governance of AI for Health, ISO/IEC 42001.`,

    "Patient Privacy & Consent": `Dynamic, granular consent systems. Patients can adjust preferences over time.
Reference: Pan-Canadian AI for Health (AI4H) Guiding Principles.`,

    "Cybersecurity & Resilience": `Embed cybersecurity-by-design, conduct adversarial testing regularly.
Reference: ISO/IEC 27001, NIST AI Risk Management Framework.`,

    "Legislative and Regulatory Reforms": `Modernize PIPEDA and PHIPA to require:
- Dynamic consent mechanisms
- AI-specific liability standards
- Mandatory post-market AI surveillance`,

    "System Implementation Supports": `Support AI governance through:
- Federated sandboxes for testing
- National AI ethics and safety councils
- Open-source governance toolkit sharing`
  };

  return (
    <div className="p-6 md:p-12 space-y-8">
      <motion.h1 className="text-4xl font-bold text-center" initial={{ opacity: 0 }} animate={{ opacity: 1 }}>
        Adaptive AI Governance Framework
      </motion.h1>
      <motion.p className="text-center text-lg max-w-3xl mx-auto" initial={{ opacity: 0 }} animate={{ opacity: 1 }}>
        Building a future-proof, dynamic, and ethical AI governance model for healthcare.
      </motion.p>
      <div className="grid md:grid-cols-3 gap-6">
        {sections.map((section) => (
          <Card key={section.title}>
            <CardContent className="p-4 space-y-4">
              <h2 className="text-2xl font-semibold">{section.title}</h2>
              {section.items.map((item) => (
                <Button 
                  key={item} 
                  variant="outline" 
                  className="w-full justify-start text-left"
                  onClick={() => setSelectedSection(item)}
                >
                  {item}
                </Button>
              ))}
            </CardContent>
          </Card>
        ))}
      </div>
      {selectedSection && (
        <motion.div 
          className="bg-gray-100 rounded-2xl p-6 mt-8 shadow-md space-y-4" 
          initial={{ y: 20, opacity: 0 }} 
          animate={{ y: 0, opacity: 1 }}
        >
          <h3 className="text-2xl font-bold">{selectedSection}</h3>
          <p className="text-lg whitespace-pre-line">{descriptions[selectedSection]}</p>
          <Button variant="ghost" className="mt-4" onClick={() => setSelectedSection(null)}>Close</Button>
        </motion.div>
      )}
    </div>
  );
}
