<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Future-Proof Healthcare AI Governance Framework</title>
<style>
/* --- Styling same as before, keeping everything consistent --- */
* { margin: 0; padding: 0; box-sizing: border-box; }
body { font-family: 'Inter', system-ui, -apple-system, sans-serif; line-height: 1.6; color: #1a1a1a; background: #f7fafc; }
.hero { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 6rem 2rem; text-align: center; }
.hero h1 { font-size: 3.5rem; margin-bottom: 1rem; line-height: 1.2; }
.hero p { font-size: 1.5rem; margin-bottom: 2rem; opacity: 0.9; }
.intro-expanded, .intro, .framework, .implementation, .global-alignment { max-width: 1200px; margin: 4rem auto; padding: 0 2rem; }
.intro-expanded h2 { font-size: 2rem; margin-bottom: 1rem; }
.intro-expanded p { margin-bottom: 2rem; }
.intro { display: grid; grid-template-columns: repeat(3, 1fr); gap: 2rem; }
.intro-card { background: white; padding: 2rem; border-radius: 10px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1); }
.framework-grid { display: grid; grid-template-columns: repeat(3, 1fr); gap: 2rem; }
.framework-section { background: white; padding: 2rem; border-radius: 10px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1); }
.framework-item { padding: 1rem; margin: 0.5rem 0; background: #f8f9fa; border-radius: 8px; cursor: pointer; transition: all 0.3s ease; }
.framework-item:hover { background: #e9ecef; transform: translateY(-2px); }
.content-box { display: none; background: white; padding: 2rem; margin-top: 2rem; border-radius: 10px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1); }
.content-box.active { display: block; animation: fadeIn 0.3s ease; }
.council-grid ul { padding-left: 20px; }
.global-alignment ul { padding-left: 20px; text-align: left; }
.toolkit-section { margin-top: 2rem; background: white; padding: 2rem; border-radius: 10px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1); }
@keyframes fadeIn { from { opacity: 0; transform: translateY(10px); } to { opacity: 1; transform: translateY(0); } }
</style>
</head>

<body>

<!-- Hero Section -->
<section class="hero">
  <h1>Future-Proof Healthcare AI Governance</h1>
  <p>An Adaptive Framework for Safe, Ethical Innovation</p>
</section>

<!-- Expanded Introduction -->
<section class="intro-expanded">
  <h2>Introduction</h2>
  <p>Artificial Intelligence (AI) is rapidly transforming healthcare, offering new capabilities in diagnosis, treatment planning, and system optimization. However, healthcare AI poses unique governance challenges: iterative learning, dynamic datasets, opaque models, and patient privacy risks demand more than static regulatory frameworks. Without adaptive oversight, both clinical outcomes and public trust are at risk.</p>

  <p>This framework is designed primarily for the Canadian healthcare context, aligning with national policies like PHIPA, PIPEDA, and Pan-Canadian AI Principles. However, its structure and safeguards are informed by global best practices, making it highly adaptable for international healthcare systems striving to safely harness AI technologies.</p>
</section>

<!-- Triple Cards: Problem | Need | Opportunity -->
<section class="intro">
  <div class="intro-card">
    <h3>The Problem</h3>
    <p>Healthcare AI implementations lack consistent governance frameworks, creating risks for patient safety, equity, and privacy. Existing regulations like PHIPA and PIPEDA do not fully account for iterative AI learning models, dynamic datasets, or shifting liability across stakeholders.</p>
  </div>
  <div class="intro-card">
    <h3>The Need</h3>
    <p>Healthcare demands an Adaptive AI Governance Framework built around the AI lifecycle, risk-tiered to context, continuously embedding human oversight, and addressing consent, bias, accountability, and cybersecurity at every lifecycle stage.</p>
  </div>
  <div class="intro-card">
    <h3>The Opportunity</h3>
    <p>Canada can lead globally by pioneering a future-proof AI governance model, safeguarding patient rights and safety while enabling trustworthy innovation and setting global benchmarks for responsible AI in healthcare.</p>
  </div>
</section>

<!-- Call to Action -->
<section class="intro-expanded">
  <h2>Call to Action</h2>
  <p>We call on policymakers, healthcare leaders, technology developers, and researchers to implement lifecycle-aligned, risk-adaptive governance for all healthcare AI systems, modernize consent and accountability frameworks, and support open-source governance toolkit development.</p>
</section>

<!-- Framework Section -->
<section class="framework">
<h2>Adaptive AI Governance Framework</h2>
  <section class="intro-expanded">
  <p>This framework is structured to guide stakeholders through critical aspects of AI governance in healthcare. When considering the development of a new AI solution or integrating an existing tool, the Lifecycle Stages outline the technical checkpoints across design and deployment. The Governance Pillars define ethical, legal, and operational safeguards applicable at any point. The Policy Recommendations focus on systemic reforms needed to build an environment where safe and effective AI innovation can thrive. Multi-level governance — spanning individual systems to national policy — is crucial to enable responsible development and minimize risks, ultimately empowering a safer, AI-driven healthcare future.</p>

  <p><em>Click through each topic below to expand guidance details, including descriptions, best practices, risk mitigation strategies, and helpful resources.</em></p>
</section>
<div class="framework-grid">

<!-- Card 1: Lifecycle Stages -->
<div class="framework-section">
<h3>Lifecycle Stages</h3>
<div class="framework-item" onclick="showContent('problem-definition')">Problem Definition</div>
<div class="framework-item" onclick="showContent('data-collection')">Data Collection</div>
<div class="framework-item" onclick="showContent('model-development')">Model Development</div>
<div class="framework-item" onclick="showContent('deployment-integration')">Deployment & Integration</div>
<div class="framework-item" onclick="showContent('monitoring-updating')">Monitoring & Updating</div>
<div class="framework-item" onclick="showContent('decommissioning')">Decommissioning</div>
</div>

<!-- Card 2: Governance Pillars -->
<div class="framework-section">
<h3>Governance Pillars</h3>
<div class="framework-item" onclick="showContent('data-ownership')">Data Ownership & Stewardship</div>
<div class="framework-item" onclick="showContent('liability')">Liability & Accountability</div>
<div class="framework-item" onclick="showContent('privacy-consent')">Patient Privacy & Consent</div>
<div class="framework-item" onclick="showContent('cybersecurity-resilience')">Cybersecurity & Resilience</div>
</div>

<!-- Card 3: Policy Recommendations -->
<div class="framework-section">
<h3>Policy Recommendations</h3>
<div class="framework-item" onclick="showContent('legislative-reforms')">Legislative and Regulatory Reforms</div>
<div class="framework-item" onclick="showContent('system-supports')">System Implementation Supports</div>
</div>

</div>
<div id="content-box" class="content-box"></div>
</section>

<!-- Implementation Supports -->
<section class="implementation">
<h2>Implementation Supports</h2>
<div class="council-grid">
<ul>
<li><a href="https://www.canada.ca/en/health-canada.html" target="_blank">Health Canada Digital Health Secretariat</a></li>
<li><a href="https://cihr-irsc.gc.ca/e/193.html" target="_blank">Canadian Institutes of Health Research (CIHR)</a></li>
<li><a href="https://www.priv.gc.ca/en/" target="_blank">Office of the Privacy Commissioner of Canada</a></li>
<li><a href="https://www.ontariohealth.ca/" target="_blank">Ontario Health Teams AI Committees</a></li>
<li><a href="https://www.csagroup.org/" target="_blank">Canadian Standards Association (CSA Group)</a></li>
</ul>
</div>

<div class="toolkit-section">
<h3>Open Source Toolkit Downloads</h3>
<ul>
<li>Dynamic Consent Dashboard Template (Coming Soon)</li>
<li>Risk Audit Worksheet (Coming Soon)</li>
<li>Cyber Incident Response Playbook (Coming Soon)</li>
</ul>
</div>
</section>

<!-- Global Alignment Section -->
<section class="global-alignment">
<h2>Built on Global Best Practices</h2>
<p>This Adaptive AI Governance Framework has been informed by leading global standards. Future versions will integrate live API connections to continuously update governance recommendations in real-time.</p>
<ul>
<li><a href="https://www.who.int/publications/i/item/9789240029200" target="_blank">WHO Ethics and AI Governance</a></li>
<li><a href="https://oecd.ai/en" target="_blank">OECD AI Principles</a></li>
<li><a href="https://www.iso.org/standard/81228.html" target="_blank">ISO/IEC 42001 AI Management Systems</a></li>
<li><a href="https://gdpr.eu/" target="_blank">GDPR: Data Protection by Design</a></li>
</ul>
</section>

<script>
// <script>
function getContent(id) {
  const content = {
    // LIFECYCLE STAGES
    'problem-definition': {
      title: 'Problem Definition',
      description: 'Define the clinical problems AI will address, involving diverse stakeholders to align objectives with patient safety, ethics, and care quality.',
      recommendations: [
        'Establish multi-disciplinary advisory groups early.',
        'Conduct pre-design ethics and equity reviews.',
        'Define acceptable risk thresholds.'
      ],
      risks: [
        {
          risk: 'Misaligned AI goals leading to unsafe deployments.',
          mitigation: 'Stakeholder-inclusive problem scoping and risk-benefit mapping.'
        }
      ],
      resources: [
        '<a href="https://oecd.ai/en/dashboards" target="_blank">OECD AI Guidelines</a>'
      ]
    },
    'data-collection': {
      title: 'Data Collection',
      description: 'Ensure data sourcing is representative, bias-audited, and consented under dynamic governance models supporting patient control.',
      recommendations: [
        'Perform bias audits at collection phase.',
        'Implement dynamic consent frameworks.',
        'Maintain detailed provenance logs.'
      ],
      risks: [
        {
          risk: 'Training AI on biased or incomplete datasets.',
          mitigation: 'Mandatory pre-training data quality and equity audits.'
        }
      ],
      resources: [
        '<a href="https://www.nist.gov/itl/ai-risk-management-framework" target="_blank">NIST AI Risk Management Framework</a>'
      ]
    },
    'model-development': {
      title: 'Model Development',
      description: 'Prioritize explainability, transparency, and multi-site validation to mitigate overfitting and support safe, reliable AI in healthcare settings.',
      recommendations: [
        'Integrate explainability-by-design.',
        'Externally validate models before use.',
        'Disclose model assumptions, risks, and biases.'
      ],
      risks: [
        {
          risk: 'Opaque models causing clinician distrust or inappropriate reliance.',
          mitigation: 'Human-readable model rationales and layered validation.'
        }
      ],
      resources: [
        '<a href="https://www.iso.org/standard/81228.html" target="_blank">ISO/IEC 42001 AI Standard</a>'
      ]
    },
    'deployment-integration': {
      title: 'Deployment & Integration',
      description: 'Align AI tool workflows to clinical practice standards, embed human-in-the-loop review, and ensure clearly delineated liability pathways.',
      recommendations: [
        'Pilot tools iteratively before full deployment.',
        'Document shared clinical responsibility models.',
        'Train users on fallback processes.'
      ],
      risks: [
        {
          risk: 'Poor integration leading to decision fatigue or errors.',
          mitigation: 'Usability testing and iterative refinement during pilots.'
        }
      ],
      resources: [
        '<a href="https://www.health.gov.on.ca/en/pro/programs/connectedcare/oht/" target="_blank">Ontario Health Teams Guidance</a>'
      ]
    },
    'monitoring-updating': {
      title: 'Monitoring & Updating',
      description: 'Mandate continuous post-market surveillance, model drift detection, and re-validation against evolving clinical standards.',
      recommendations: [
        'Annual real-world performance revalidation.',
        'Implement automated drift alarms.',
        'Mandate incident reporting linked to AI performance.'
      ],
      risks: [
        {
          risk: 'Unnoticed performance decay harming patients.',
          mitigation: 'Post-deployment monitoring and drift-triggered audits.'
        }
      ],
      resources: [
        '<a href="https://www.who.int/publications/i/item/9789240029200" target="_blank">WHO AI Governance Guidelines</a>'
      ]
    },
    'decommissioning': {
      title: 'Decommissioning',
      description: 'Create responsible sunset plans for AI systems, ensuring safe retirement and transition without compromising patient care continuity.',
      recommendations: [
        'Publish decommissioning criteria at launch.',
        'Notify patients/providers of AI retirement.',
        'Securely archive AI models and outputs.'
      ],
      risks: [
        {
          risk: 'Outdated AI continuing unnoticed.',
          mitigation: 'Scheduled decommissioning audits and sunset reviews.'
        }
      ],
      resources: [
        '<a href="https://www.canada.ca/en/government/system-digital/artificial-intelligence.html" target="_blank">Canada Digital Government AI Policy</a>'
      ]
    },
    // GOVERNANCE PILLARS
    'data-ownership': {
      title: 'Data Ownership & Stewardship',
      description: 'Ensure patients retain control over their health data throughout AI development, deployment, and use.',
      recommendations: [
        'Support patient consent dashboards.',
        'Build federated, privacy-preserving data architectures.',
        'Track all data use/access logs transparently.'
      ],
      risks: [
        {
          risk: 'Loss of patient trust due to opaque data sharing.',
          mitigation: 'Radical transparency and consent renewals.'
        }
      ],
      resources: [
        '<a href="https://oecd.ai/en/dashboards/canada" target="_blank">OECD AI Dashboard: Canada</a>'
      ]
    },
    'liability': {
      title: 'Liability & Accountability',
      description: 'Assign clear shared liability across AI developers, vendors, institutions, and clinical users with enforceable contracts.',
      recommendations: [
        'Mandate shared liability frameworks.',
        'Define human fallback oversight responsibilities.',
        'Insurance policies tailored to AI-related incidents.'
      ],
      risks: [
        {
          risk: 'No clear accountability during AI-caused harm events.',
          mitigation: 'Pre-deployment contractual accountability frameworks.'
        }
      ],
      resources: [
        '<a href="https://www.iso.org/obp/ui#iso:std:iso-iec:27001:ed-2:v1:en" target="_blank">ISO/IEC 27001 Security Standards</a>'
      ]
    },
    'privacy-consent': {
      title: 'Patient Privacy & Consent',
      description: 'Implement dynamic, tiered consent to allow patients ongoing control over how their data is used in evolving AI systems.',
      recommendations: [
        'Deploy patient-facing consent portals.',
        'Enable granular opt-outs by service or dataset.',
        'Audit consent use compliance annually.'
      ],
      risks: [
        {
          risk: 'Secondary use of data without patient reconsent.',
          mitigation: 'Dynamic consent linked to data-use auditing tools.'
        }
      ],
      resources: [
        '<a href="https://gdpr.eu/" target="_blank">GDPR Privacy by Design</a>'
      ]
    },
    'cybersecurity-resilience': {
      title: 'Cybersecurity & Resilience',
      description: 'Harden AI systems against adversarial attacks, model tampering, and cyber vulnerabilities at every lifecycle stage.',
      recommendations: [
        'Mandate adversarial robustness testing.',
        'Develop AI-specific cyber incident response plans.',
        'Isolate and encrypt sensitive AI models.'
      ],
      risks: [
        {
          risk: 'Model poisoning or privacy breach attacks.',
          mitigation: 'Periodic penetration testing and model robustness scoring.'
        }
      ],
      resources: [
        '<a href="https://www.iso.org/standard/81228.html" target="_blank">ISO/IEC 42001 Security for AI Systems</a>'
      ]
    },
    // POLICY RECOMMENDATIONS
    'legislative-reforms': {
      title: 'Legislative and Regulatory Reforms',
      description: 'Modernize PHIPA/PIPEDA and national healthcare regulations to address AI-specific challenges in liability, privacy, and post-deployment accountability.',
      recommendations: [
        'Create risk-tiered AI regulatory pathways.',
        'Mandate dynamic consent and lifecycle compliance checks.',
        'Update data protection laws to account for continuously learning systems.'
      ],
      risks: [
        {
          risk: 'Static regulations failing against dynamic AI risks.',
          mitigation: 'Laws requiring periodic AI policy re-evaluation tied to technical developments.'
        }
      ],
      resources: [
        '<a href="https://www.canada.ca/en/health-canada/services/health-canada-modernization/artificial-intelligence.html" target="_blank">Health Canada AI Policy Strategy</a>'
      ]
    },
    'system-supports': {
      title: 'System Implementation Supports',
      description: 'Establish governance councils, AI health sandboxes, and open-source toolkits to operationalize safe and ethical AI healthcare innovation.',
      recommendations: [
        'Fund national AI health sandboxes for real-world testing.',
        'Support Health Canada and CIHR advisory groups.',
        'Distribute open-source risk audit and consent management tools.'
      ],
      risks: [
        {
          risk: 'Fragmented, inconsistent local AI governance across regions.',
          mitigation: 'Pan-Canadian governance council establishment and toolkit sharing.'
        }
      ],
      resources: [
        '<a href="https://cihr-irsc.gc.ca/e/193.html" target="_blank">CIHR AI Health Initiatives</a>'
      ]
    }
  };
  return content[id];
}

function showContent(id) {
  const contentBox = document.getElementById('content-box');
  const content = getContent(id);

  if (content) {
    contentBox.innerHTML = `
      <h3>${content.title}</h3>
      <div class="content-grid">
        <div>
          <h4>Description</h4>
          <p>${content.description}</p>
        </div>
        <div>
          <h4>Recommendations</h4>
          <ul>
            ${content.recommendations.map(rec => `<li>${rec}</li>`).join('')}
          </ul>
        </div>
        <div>
          <h4>Risks & Mitigations</h4>
          ${content.risks.map(risk => `
            <div>
              <p><strong>Risk:</strong> ${risk.risk}</p>
              <p><strong>Mitigation:</strong> ${risk.mitigation}</p>
            </div>
          `).join('')}
        </div>
        <div>
          <h4>Resources</h4>
          ${content.resources.map(resource => `<p>${resource}</p>`).join('')}
        </div>
      </div>
    `;
    contentBox.classList.add('active');
  }
}
</script>

</script>

</body>
</html>
