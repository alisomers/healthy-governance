<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Future-Proof Healthcare AI Governance Framework</title>
<style>
/* --- Your Existing Styles --- */
* { margin: 0; padding: 0; box-sizing: border-box; }
body { font-family: 'Inter', system-ui, -apple-system, sans-serif; line-height: 1.6; color: #1a1a1a; background: #f7fafc; }
.hero { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 6rem 2rem; text-align: center; }
.hero h1 { font-size: 3.5rem; margin-bottom: 1rem; line-height: 1.2; }
.hero p { font-size: 1.5rem; margin-bottom: 2rem; opacity: 0.9; }
.intro-expanded, .intro, .framework, .implementation, .global-alignment { max-width: 1200px; margin: 4rem auto; padding: 0 2rem; }
.intro-expanded h2 { font-size: 2rem; margin-bottom: 1rem; }
.intro-expanded p { margin-bottom: 2rem; }
.intro { display: grid; grid-template-columns: repeat(3, 1fr); gap: 2rem; }
.intro-card { background: white; padding: 2rem; border-radius: 10px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1); }
.framework-grid { display: grid; grid-template-columns: repeat(2, 1fr); gap: 2rem; }
.framework-section { background: white; padding: 2rem; border-radius: 10px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1); }
.framework-item { padding: 1rem; margin: 0.5rem 0; background: #f8f9fa; border-radius: 8px; cursor: pointer; transition: all 0.3s ease; }
.framework-item:hover { background: #e9ecef; transform: translateY(-2px); }
.content-box { display: none; background: white; padding: 2rem; margin-top: 2rem; border-radius: 10px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1); }
.content-box.active { display: block; animation: fadeIn 0.3s ease; }
.council-grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 2rem; margin-top: 2rem; }
.toolkit-section { margin-top: 2rem; background: white; padding: 2rem; border-radius: 10px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1); }
.global-alignment { background: #f8f9fa; padding: 4rem 2rem; text-align: center; }
.partner-logos { display: flex; flex-direction: column; align-items: center; gap: 1rem; margin-top: 2rem; }
.button { padding: 1rem 2rem; background: #4299e1; color: white; border: none; border-radius: 8px; font-weight: 500; cursor: pointer; transition: all 0.3s ease; }
.button:hover { background: #3182ce; transform: translateY(-2px); }
@keyframes fadeIn { from { opacity: 0; transform: translateY(10px); } to { opacity: 1; transform: translateY(0); } }
</style>
</head>

<body>

<!-- Hero Section -->
<section class="hero">
  <h1>Future-Proof Healthcare AI Governance</h1>
  <p>An Adaptive Framework for Safe, Ethical Innovation</p>
</section>

<!-- Introduction Section (Expanded) -->
<section class="intro-expanded">
  <h2>Introduction</h2>
  <p>Artificial Intelligence (AI) is rapidly transforming healthcare, offering new capabilities in diagnosis, treatment planning, and system optimization. However, healthcare AI poses unique governance challenges: iterative learning, dynamic datasets, opaque models, and patient privacy risks demand more than static regulatory frameworks. Without adaptive oversight, both clinical outcomes and public trust are at risk.</p>

  <h2>The Problem</h2>
  <p>Current healthcare regulations, including PHIPA and PIPEDA, were not designed for self-evolving AI models. Gaps exist in post-deployment monitoring, dynamic patient consent, distributed liability, and cybersecurity resiliency. Traditional "one-time" approvals leave systems vulnerable to performance decay and ethical breaches.</p>

  <h2>The Need</h2>
  <p>Healthcare requires an Adaptive AI Governance Framework: built around the AI lifecycle, risk-tiered and context-specific, embedding human oversight continuously, and addressing consent, bias, accountability, and cybersecurity at every stage.</p>

  <h2>The Opportunity</h2>
  <p>Canada can lead globally by adopting a future-proof model: safeguarding patient safety and equity, enabling trustworthy innovation, and creating exportable governance standards for global health AI.</p>

  <h2>Call to Action</h2>
  <p>We call on policymakers, healthcare leaders, technology developers, and researchers to implement lifecycle-aligned, risk-adaptive governance for all AI healthcare systems, modernize consent and accountability frameworks, and support national governance councils and open-source toolkit development.</p>
</section>

<!-- Existing Intro Cards Section -->
<section class="intro">
  <div class="intro-card">
    <h3>The Problem</h3>
    <p>Healthcare AI implementations lack consistent governance frameworks, creating risks for patient safety and privacy.</p>
  </div>
  <div class="intro-card">
    <h3>The Need</h3>
    <p>An adaptive, comprehensive approach to AI governance is essential as healthcare systems increasingly rely on AI technologies.</p>
  </div>
  <div class="intro-card">
    <h3>The Opportunity</h3>
    <p>Canada can lead globally in establishing ethical, safe, and scalable AI governance in healthcare.</p>
  </div>
</section>

<!-- Framework Section -->
<section class="framework">
<h2>Adaptive AI Governance Framework</h2>
<div class="framework-grid">
<div class="framework-section">
<h3>Lifecycle Stages</h3>
<div class="framework-item" onclick="showContent('problem-definition')">Problem Definition</div>
<div class="framework-item" onclick="showContent('data-collection')">Data Collection</div>
<div class="framework-item" onclick="showContent('model-development')">Model Development</div>
<div class="framework-item" onclick="showContent('deployment-integration')">Deployment & Integration</div>
<div class="framework-item" onclick="showContent('monitoring-updating')">Monitoring & Updating</div>
<div class="framework-item" onclick="showContent('decommissioning')">Decommissioning</div>
</div>
<div class="framework-section">
<h3>Governance Pillars</h3>
<div class="framework-item" onclick="showContent('data-ownership')">Data Ownership & Stewardship</div>
<div class="framework-item" onclick="showContent('liability')">Liability & Accountability</div>
<div class="framework-item" onclick="showContent('privacy-consent')">Patient Privacy & Consent</div>
<div class="framework-item" onclick="showContent('cybersecurity-resilience')">Cybersecurity & Resilience</div>
<div class="framework-item" onclick="showContent('policy-recommendations')">Policy Recommendations</div>
</div>
</div>
<div id="content-box" class="content-box"></div>
</section>

<!-- Implementation Support -->
<section class="implementation">
<h2>Implementation Supports</h2>
<p>Key councils contributing to adaptive AI governance:</p>
<div class="council-grid">
<div>Health Canada Digital Health Secretariat</div>
<div>Canadian Institutes of Health Research (CIHR)</div>
<div>Office of the Privacy Commissioner of Canada</div>
<div>Ontario Health Teams AI Committees</div>
<div>Canadian Standards Association (CSA Group)</div>
</div>

<div class="toolkit-section">
<h3>Open Source Toolkit Downloads</h3>
<ul>
<li><a href="#">Dynamic Consent Dashboard Template (Coming Soon)</a></li>
<li><a href="#">Risk Audit Worksheet (Coming Soon)</a></li>
<li><a href="#">Cyber Incident Response Playbook (Coming Soon)</a></li>
</ul>
</div>
</section>

<!-- Global Alignment Section -->
<section class="global-alignment">
<h2>Built on Global Best Practices</h2>
<div class="partner-logos">
<a href="https://www.who.int/publications/i/item/9789240029200" target="_blank">WHO Ethics & AI Governance</a>
<a href="https://oecd.ai/en" target="_blank">OECD AI Principles</a>
<a href="https://www.iso.org/standard/81228.html" target="_blank">ISO/IEC 42001 AI Standards</a>
<a href="https://gdpr.eu/" target="_blank">GDPR Data Protection by Design</a>
</div>
</section>

<script>
// <script>
function getContent(id) {
  const content = {
    // Lifecycle Stages
    'problem-definition': {
      title: 'Problem Definition',
      description: 'Collaboratively define clinical problems AI systems will address, including acceptable risk thresholds and scope of use.',
      recommendations: [
        'Engage clinicians, patients, ethicists early in problem framing.',
        'Define clear success and safety metrics pre-development.',
        'Perform ethics review before model design.'
      ],
      risks: [
        {
          risk: 'Misaligned problem definition leading to unsafe AI behavior (e.g., IBM Watson Oncology failures).',
          mitigation: 'Mandate stakeholder co-design and risk-benefit mapping early.'
        }
      ],
      resources: [
        '<a href="https://oecd.ai/en/dashboards" target="_blank">OECD AI Guidelines</a>'
      ]
    },
    'data-collection': {
      title: 'Data Collection',
      description: 'Secure, bias-mitigated, consented datasets are critical to ensure trustworthy AI systems.',
      recommendations: [
        'Audit datasets for bias and gaps before training.',
        'Implement dynamic, ongoing patient consent mechanisms.',
        'Track data provenance and custodianship responsibilities.'
      ],
      risks: [
        {
          risk: 'Biased datasets amplifying health disparities (e.g., Science 2019 Risk Study).',
          mitigation: 'Continuous bias audits and representative data sourcing.'
        }
      ],
      resources: [
        '<a href="https://www.nist.gov/itl/ai-risk-management-framework" target="_blank">NIST AI Risk Management Framework</a>'
      ]
    },
    'model-development': {
      title: 'Model Development',
      description: 'Prioritize explainability, transparency, and robust multi-site validation before deployment.',
      recommendations: [
        'Conduct multi-institutional validation studies.',
        'Adopt explainability-by-design principles.',
        'Clearly define system limitations and uses.'
      ],
      risks: [
        {
          risk: 'Overfitting risks and clinical deployment failures (e.g., Google Retinal AI underperformance).',
          mitigation: 'External validation across multiple sites and populations.'
        }
      ],
      resources: [
        '<a href="https://www.iso.org/standard/81228.html" target="_blank">ISO/IEC 42001 AI Standard</a>'
      ]
    },
    'deployment-integration': {
      title: 'Deployment & Integration',
      description: 'Seamlessly integrate AI into clinical workflows, ensuring human oversight and liability clarity.',
      recommendations: [
        'Use human-in-the-loop supervision.',
        'Define clinical fallback processes.',
        'Conduct workflow usability testing.'
      ],
      risks: [
        {
          risk: 'Workflow mismatches and clinical fatigue leading to adverse events.',
          mitigation: 'Iterative piloting and clinician feedback integration.'
        }
      ],
      resources: [
        '<a href="https://www.health.gov.on.ca/en/pro/programs/connectedcare/oht/" target="_blank">Ontario Health Teams AI Guidelines</a>'
      ]
    },
    'monitoring-updating': {
      title: 'Monitoring & Updating',
      description: 'Mandate continuous model monitoring, real-world validation, and alert systems for drift.',
      recommendations: [
        'Set performance re-validation annually.',
        'Integrate real-world data into AI audit cycles.',
        'Enable continuous learning with safeguards.'
      ],
      risks: [
        {
          risk: 'Silent performance degradation over time.',
          mitigation: 'Proactive surveillance and drift detection protocols.'
        }
      ],
      resources: [
        '<a href="https://www.who.int/publications/i/item/9789240029200" target="_blank">WHO AI Governance Report</a>'
      ]
    },
    'decommissioning': {
      title: 'Decommissioning',
      description: 'Responsibly retire outdated AI systems and notify affected stakeholders.',
      recommendations: [
        'Define sunset timelines at deployment.',
        'Securely archive model outputs.',
        'Communicate decommissioning to patients and providers.'
      ],
      risks: [
        {
          risk: 'Old AI systems persisting in clinical workflows post-retirement.',
          mitigation: 'Scheduled decommissioning audits and governance oversight.'
        }
      ],
      resources: [
        '<a href="https://canada.ca/en/government/system-digital/artificial-intelligence.html" target="_blank">Canada AI Policy</a>'
      ]
    },
    // Governance Pillars
    'data-ownership': {
      title: 'Data Ownership & Stewardship',
      description: 'Patients must retain meaningful ownership and control over their health data in AI systems.',
      recommendations: [
        'Implement decentralized, federated data stewardship models.',
        'Support transparent access and dynamic consent dashboards.'
      ],
      risks: [
        {
          risk: 'Data monopolization by vendors or hospitals.',
          mitigation: 'Federated architectures with real-time patient permissions.'
        }
      ],
      resources: [
        '<a href="https://oecd.ai/en/dashboards/canada" target="_blank">OECD AI Dashboard: Canada</a>'
      ]
    },
    'liability': {
      title: 'Liability & Accountability',
      description: 'Clearly distribute legal responsibility among developers, providers, and institutions.',
      recommendations: [
        'Mandate multi-party AI liability contracts.',
        'Embed explicit human fallback review for high-risk decisions.'
      ],
      risks: [
        {
          risk: 'Unclear accountability when AI systems fail.',
          mitigation: 'Predefined incident pathways and joint risk insurance models.'
        }
      ],
      resources: [
        '<a href="https://www.iso.org/obp/ui#iso:std:iso-iec:27001:ed-2:v1:en" target="_blank">ISO/IEC 27001 Information Security Standard</a>'
      ]
    },
    'privacy-consent': {
      title: 'Patient Privacy & Consent',
      description: 'Ensure dynamic, tiered consent for patient data use across the full AI lifecycle.',
      recommendations: [
        'Implement dynamic consent dashboards with opt-in/opt-out.',
        'Review consent compliance annually.'
      ],
      risks: [
        {
          risk: 'Secondary data use without updated patient consent.',
          mitigation: 'Mandatory dynamic consent controls with user visibility.'
        }
      ],
      resources: [
        '<a href="https://gdpr.eu/" target="_blank">GDPR Data Protection Resources</a>'
      ]
    },
    'cybersecurity-resilience': {
      title: 'Cybersecurity & Resilience',
      description: 'Embed security-by-design principles and conduct adversarial robustness testing.',
      recommendations: [
        'Mandate adversarial penetration testing pre-deployment.',
        'Develop rapid AI-specific incident response playbooks.'
      ],
      risks: [
        {
          risk: 'Model poisoning or system hijacking by attackers.',
          mitigation: 'Red-teaming exercises and layered model security defenses.'
        }
      ],
      resources: [
        '<a href="https://www.iso.org/standard/81228.html" target="_blank">ISO/IEC 42001 Cybersecurity AI Management</a>'
      ]
    },
    'policy-recommendations': {
      title: 'Policy Recommendations',
      description: 'Modernize laws and build system supports for adaptive governance and AI safety in healthcare.',
      recommendations: [
        'Amend PHIPA/PIPEDA to address AI-specific risks.',
        'Create federated AI testing sandboxes.',
        'Fund open-source adaptive governance toolkits.'
      ],
      risks: [
        {
          risk: 'Static regulatory frameworks failing to protect evolving AI.',
          mitigation: 'Lifecycle-aligned, tiered oversight built into law.'
        }
      ],
      resources: [
        '<a href="https://www.canada.ca/en/health-canada/services/health-canada-modernization/artificial-intelligence.html" target="_blank">Health Canada AI Strategy</a>'
      ]
    }
  };
  return content[id];
}

function showContent(id) {
  const contentBox = document.getElementById('content-box');
  const content = getContent(id);

  if (content) {
    contentBox.innerHTML = `
      <h3>${content.title}</h3>
      <div class="content-grid">
        <div>
          <h4>Description</h4>
          <p>${content.description}</p>
        </div>
        <div>
          <h4>Recommendations</h4>
          <ul>
            ${content.recommendations.map(rec => `<li>${rec}</li>`).join('')}
          </ul>
        </div>
        <div>
          <h4>Risks & Mitigations</h4>
          ${content.risks.map(risk => `
            <div>
              <p><strong>Risk:</strong> ${risk.risk}</p>
              <p><strong>Mitigation:</strong> ${risk.mitigation}</p>
            </div>
          `).join('')}
        </div>
        <div>
          <h4>Resources</h4>
          ${content.resources.map(resource => `<p>${resource}</p>`).join('')}
        </div>
      </div>
    `;
    contentBox.classList.add('active');
  }
}
</script>

</script>

</body>
</html>

