<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Future-Proof Healthcare AI Governance Framework</title>
<style>
/* --- Global Styles --- */
* { margin: 0; padding: 0; box-sizing: border-box; }
body { font-family: 'Inter', system-ui, sans-serif; line-height: 1.6; color: #1a1a1a; background: #f7fafc; }

/* Hero Section */
.hero { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 6rem 2rem; text-align: center; }
.hero h1 { font-size: 3.5rem; margin-bottom: 1rem; }
.hero p { font-size: 1.5rem; margin-bottom: 2rem; opacity: 0.9; }

/* Section Headings */
h2 { font-size: 2rem; margin-bottom: 1.5rem; font-weight: bold; color: #1a1a1a; }

/* Intro & Framework Sections */
.intro-expanded, .intro, .framework, .implementation, .global-alignment { max-width: 1200px; margin: 4rem auto; padding: 0 2rem; }
.intro-expanded p, .framework p, .implementation p, .global-alignment p { margin-bottom: 2rem; font-size: 1.1rem; }

/* Cards */
.intro { display: grid; grid-template-columns: repeat(3, 1fr); gap: 2rem; }
.intro-card { background: white; padding: 2rem; border-radius: 10px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1); }

/* Framework Cards */
.framework-grid { display: grid; grid-template-columns: repeat(3, 1fr); gap: 2rem; }
.framework-section { background: white; padding: 2rem; border-radius: 10px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1); }
.framework-item { padding: 1rem; margin: 0.5rem 0; background: #f8f9fa; border-radius: 8px; cursor: pointer; transition: all 0.3s ease; }
.framework-item:hover { background: #e9ecef; transform: translateY(-2px); }
.framework-item.active { background: #c3dafe; font-weight: 600; }
.arrow { display: inline-block; margin-left: 8px; transform: rotate(90deg); opacity: 0; transition: all 0.3s ease; }
.arrow.show { opacity: 1; transform: rotate(90deg) translateX(5px); }

/* Expandable Content Box */
.content-box { display: none; background: white; padding: 2rem; margin-top: 2rem; border-radius: 10px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1); }
.content-box.active { display: block; animation: fadeIn 0.3s ease; }

/* Implementation / Global Best Practices */
.council-grid ul, .global-alignment ul { padding-left: 20px; }
.toolkit-section { margin-top: 2rem; background: white; padding: 2rem; border-radius: 10px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1); }
.toolkit-section div { display: flex; flex-wrap: wrap; gap: 1.5rem; }
.toolkit-section div > div { flex: 1 1 45%; background: #f8f9fa; padding: 1rem; border-radius: 8px; text-align: center; }

/* Animations */
@keyframes fadeIn { from { opacity: 0; transform: translateY(10px); } to { opacity: 1; transform: translateY(0); } }
</style>
</head>

<body>

<!-- Hero Section -->
<section class="hero">
  <h1>Future-Proof Healthcare AI Governance</h1>
  <p>An Adaptive Framework for Safe, Ethical Innovation</p>
</section>

<!-- Expanded Introduction -->
<section class="intro-expanded">
  <h2>Introduction</h2>
  <p>Artificial Intelligence (AI) is rapidly transforming healthcare, offering new capabilities in diagnosis, treatment planning, and system optimization. However, healthcare AI poses unique governance challenges: iterative learning, dynamic datasets, opaque models, and patient privacy risks demand more than static regulatory frameworks. Without adaptive oversight, both clinical outcomes and public trust are at risk.</p>
  <p>This framework is designed primarily for the Canadian healthcare context, but is adaptable globally based on shared principles of ethical, safe, and human-centered AI governance.</p>
</section>

<!-- Triple Cards: Problem | Need | Opportunity -->
<section class="intro">
  <div class="intro-card">
    <h3>The Problem</h3>
    <p>Healthcare AI implementations lack consistent governance frameworks, creating risks for patient safety, equity, and privacy. Existing regulations like PHIPA and PIPEDA do not fully account for iterative AI learning models, dynamic datasets, or shifting liability across stakeholders.</p>
  </div>
  <div class="intro-card">
    <h3>The Need</h3>
    <p>Healthcare demands an Adaptive AI Governance Framework built around the AI lifecycle, risk-tiered to context, continuously embedding human oversight, and addressing consent, bias, accountability, and cybersecurity at every lifecycle stage.</p>
  </div>
  <div class="intro-card">
    <h3>The Opportunity</h3>
    <p>Canada can lead globally by pioneering a future-proof AI governance model, safeguarding patient rights and safety while enabling trustworthy innovation and setting global benchmarks for responsible AI in healthcare.</p>
  </div>
</section>

<!-- Call to Action -->
<section class="intro-expanded">
  <h2>Call to Action</h2>
  <p>We call on policymakers, healthcare leaders, technology developers, and researchers to implement lifecycle-aligned, risk-adaptive governance for all healthcare AI systems, modernize consent and accountability frameworks, and support open-source governance toolkit development.</p>
</section>

<!-- Framework Section -->
<section class="framework">
<h2>Adaptive AI Governance Framework</h2>
<p>This framework guides users to apply governance measures at every phase of the AI lifecycle. Lifecycle Stages focus on technical development checkpoints, Governance Pillars ensure ethical and privacy protections, and Policy Recommendations advocate for system-wide reforms. Click through the sections below to expand and explore guidance, risks, and resources.</p>

<div class="framework-grid">
<!-- Card 1: Lifecycle Stages -->
<div class="framework-section">
<h3>Lifecycle Stages</h3>
<div class="framework-item" onclick="showContent('problem-definition')">Problem Definition</div>
<div class="framework-item" onclick="showContent('data-collection')">Data Collection</div>
<div class="framework-item" onclick="showContent('model-development')">Model Development</div>
<div class="framework-item" onclick="showContent('deployment-integration')">Deployment & Integration</div>
<div class="framework-item" onclick="showContent('monitoring-updating')">Monitoring & Updating</div>
<div class="framework-item" onclick="showContent('decommissioning')">Decommissioning</div>
</div>

<!-- Card 2: Governance Pillars -->
<div class="framework-section">
<h3>Governance Pillars</h3>
<div class="framework-item" onclick="showContent('data-ownership')">Data Ownership & Stewardship</div>
<div class="framework-item" onclick="showContent('liability')">Liability & Accountability</div>
<div class="framework-item" onclick="showContent('privacy-consent')">Patient Privacy & Consent</div>
<div class="framework-item" onclick="showContent('cybersecurity-resilience')">Cybersecurity & Resilience</div>
</div>

<!-- Card 3: Policy Recommendations -->
<div class="framework-section">
<h3>Policy Recommendations</h3>
<div class="framework-item" onclick="showContent('legislative-reforms')">Legislative and Regulatory Reforms</div>
<div class="framework-item" onclick="showContent('system-supports')">System Implementation Supports</div>
</div>
</div>

<div id="content-box" class="content-box"></div>
</section>

<!-- Implementation Supports -->
<section class="implementation">
<h2>Implementation Supports</h2>
<p>AI governance requires collaboration across federal agencies, research institutions, and standards organizations. These bodies provide the necessary oversight, research, and frameworks to ensure that AI in healthcare is deployed safely, ethically, and effectively.</p>
<div class="council-grid">
<ul>
<li><a href="https://www.canada.ca/en/health-canada.html" target="_blank">Health Canada Digital Health Secretariat</a></li>
<li><a href="https://cihr-irsc.gc.ca/e/193.html" target="_blank">Canadian Institutes of Health Research (CIHR)</a></li>
<li><a href="https://www.priv.gc.ca/en/" target="_blank">Office of the Privacy Commissioner of Canada</a></li>
<li><a href="https://www.canada.ca/en/health-canada/corporate/transparency/health-agreements/pan-canadian-ai-guiding-principles.html" target="_blank">Pan-Canadian AI Guiding Principles</a></li>
<li><a href="https://www.csagroup.org/" target="_blank">Canadian Standards Association (CSA Group)</a></li>
</ul>
</div>

<!-- Toolkit Downloads -->
<div class="toolkit-section">
<h3>Open Source Toolkit Downloads</h3>
<div>
  <div><strong>Dynamic Consent Dashboard Template</strong><br>(Coming Soon)</div>
  <div><strong>Risk Audit Worksheet</strong><br>(Coming Soon)</div>
  <div><strong>Cyber Incident Response Playbook</strong><br>(Coming Soon)</div>
  <div><strong>Patient Consent Form Template</strong><br>(Coming Soon)</div>
</div>
</div>
</section>

<!-- Global Alignment Section -->
<section class="global-alignment">
<h2>Built on Global Best Practices</h2>
<p>This Adaptive AI Governance Framework has been informed by leading global standards. Future versions will integrate live API connections to continuously update governance recommendations in real-time.</p>
<ul>
<li><a href="https://www.who.int/publications/i/item/9789240029200" target="_blank">WHO Ethics and AI Governance</a></li>
<li><a href="https://oecd.ai/en" target="_blank">OECD AI Principles</a></li>
<li><a href="https://www.iso.org/standard/81228.html" target="_blank">ISO/IEC 42001 AI Management Systems</a></li>
<li><a href="https://gdpr.eu/" target="_blank">GDPR: Data Protection by Design</a></li>
</ul>
</section>

<script>
function getContent(id) {
const content = {
'problem-definition': {
title: 'Problem Definition',
description: 'Define the clinical problems AI will address, involving diverse stakeholders to align objectives with patient safety, ethics, and care quality.',
recommendations: ['Establish multi-disciplinary advisory groups early.', 'Conduct pre-design ethics and equity reviews.', 'Define acceptable risk thresholds.'],
risks: [{ risk: 'Misaligned AI goals leading to unsafe deployments (ex. IBM Watson for Oncology incorrectly recommended unsafe cancer treatments due to incomplete real-world clinical data during initial design phase)', mitigation: 'Stakeholder-inclusive problem scoping and risk-benefit mapping.' }],
resources: ['<a href="https://oecd.ai/en/dashboards" target="_blank">OECD AI Guidelines</a>']
},
'data-collection': {
title: 'Data Collection',
description: 'Ensure data sourcing is representative, bias-audited, and consented under dynamic governance models supporting patient control.',
recommendations: ['Perform bias audits at collection phase.', 'Implement dynamic consent frameworks.', 'Maintain detailed provenance logs.'],
risks: [{ risk: 'Training AI on biased or incomplete datasets (ex. COVID-19 risk prediction algorithms performed worse for racial minorities because the training datasets lacked diverse patient samples)', mitigation: 'Mandatory pre-training data quality and equity audits.' }],
resources: ['<a href="https://www.nist.gov/itl/ai-risk-management-framework" target="_blank">NIST AI Risk Management Framework</a>']
},
'model-development': {
title: 'Model Development',
description: 'Prioritize explainability, transparency, and multi-site validation to mitigate overfitting and support safe, reliable AI in healthcare settings.',
recommendations: ['Integrate explainability-by-design.', 'Externally validate models before use.', 'Disclose model assumptions, risks, and biases.'],
risks: [{ risk: 'Opaque models causing clinician distrust (ex. Google Health’s AI for diabetic retinopathy failed when deployed in rural Thailand because of different image quality than the training data)', mitigation: 'Human-readable model rationales and layered validation.' }],
resources: ['<a href="https://www.iso.org/standard/81228.html" target="_blank">ISO/IEC 42001 AI Standard</a>']
},
'deployment-integration': {
title: 'Deployment & Integration',
description: 'Align AI tool workflows to clinical practice standards, embed human-in-the-loop review, and ensure clearly delineated liability pathways.',
recommendations: ['Pilot tools iteratively before full deployment.', 'Document shared clinical responsibility models.', 'Train users on fallback processes.'],
risks: [{ risk: 'Poor integration causing decision fatigue (ex. A sepsis early warning AI system (Epic) caused alarm fatigue because it integrated poorly with clinical workflows, leading clinicians to ignore true alerts)', mitigation: 'Usability testing and iterative refinement during pilots.' }],
resources: [<a href="https://nam.edu/artificial-intelligence-special-publication/" target="_blank">Artificial Intelligence in Health Care – NAM 2019</a>]
},
'monitoring-updating': {
title: 'Monitoring & Updating',
description: 'Mandate continuous post-market surveillance, model drift detection, and re-validation against evolving clinical standards.',
recommendations: ['Annual real-world performance revalidation.', 'Implement automated drift alarms.', 'Mandate incident reporting linked to AI performance.'],
risks: [{ risk: 'Unnoticed performance decay harming patients (ex. No active monitoring of a stroke prediction algorithm in the UK led to a gradual loss of accuracy over 5 years, disproportionately affecting elderly patients)', mitigation: 'Post-deployment monitoring and drift-triggered audits.' }],
resources: ['<a href="https://www.who.int/publications/i/item/9789240029200" target="_blank">WHO AI Governance Guidelines</a>']
},
'decommissioning': {
title: 'Decommissioning',
description: 'Create responsible sunset plans for AI systems, ensuring safe retirement and transition without compromising patient care continuity.',
recommendations: ['Publish decommissioning criteria at launch.', 'Notify patients/providers of AI retirement.', 'Securely archive AI models and outputs.'],
risks: [{ risk: 'Outdated AI continuing unnoticed (ex. Older clinical decision support tools for antibiotic prescribing remained live even after updated resistance data invalidated them, risking unsafe treatment choices)', mitigation: 'Scheduled decommissioning audits and sunset reviews.' }],
resources: ['<a href="https://www.canada.ca/en/government/system-digital/artificial-intelligence.html" target="_blank">Canada Digital Government AI Policy</a>']
},
'data-ownership': {
title: 'Data Ownership & Stewardship',
description: 'Ensure patients retain control over their health data throughout AI development, deployment, and use.',
recommendations: ['Support patient consent dashboards.', 'Build federated, privacy-preserving data architectures.', 'Track all data use/access logs transparently.'],
risks: [{ risk: 'Loss of patient trust due to opaque data sharing (ex. In the UK’s NHS data-sharing agreement with Google DeepMind (Royal Free Trust), patients were not properly informed about the use of their data, leading to public backlash and privacy violation findings)', mitigation: 'Radical transparency and consent renewals.' }],
resources: ['<a href="https://oecd.ai/en/dashboards/canada" target="_blank">OECD AI Dashboard: Canada</a>']
},
'liability': {
title: 'Liability & Accountability',
description: 'Assign clear shared liability across AI developers, vendors, institutions, and clinical users with enforceable contracts.',
recommendations: ['Mandate shared liability frameworks.', 'Define human fallback oversight responsibilities.', 'Insurance policies tailored to AI-related incidents.'],
risks: [{ risk: 'No clear accountability during AI-caused harm events (ex. An AI system incorrectly recommended emergency discharge for a patient who later died; legal proceedings became complex because there was no clear accountability split between software vendor and hospital)', mitigation: 'Pre-deployment contractual accountability frameworks.' }],
resources: ['<a href="https://www.iso.org/obp/ui#iso:std:iso-iec:27001:ed-2:v1:en" target="_blank">ISO/IEC 27001 Security Standards</a>']
},
'privacy-consent': {
title: 'Patient Privacy & Consent',
description: 'Implement dynamic, tiered consent to allow patients ongoing control over how their data is used in evolving AI systems.',
recommendations: ['Deploy patient-facing consent portals.', 'Enable granular opt-outs by service or dataset.', 'Audit consent use compliance annually.'],
risks: [{ risk: 'Secondary use of data without reconsent (ex. A mental health chatbot company shared sensitive patient disclosures with third parties without consent, raising serious privacy concerns)', mitigation: 'Dynamic consent linked to data-use auditing tools.' }],
resources: ['<a href="https://gdpr.eu/" target="_blank">GDPR Privacy by Design</a>']
},
'cybersecurity-resilience': {
title: 'Cybersecurity & Resilience',
description: 'Harden AI systems against adversarial attacks, model tampering, and cyber vulnerabilities at every lifecycle stage.',
recommendations: ['Mandate adversarial robustness testing.', 'Develop AI-specific cyber incident response plans.', 'Isolate and encrypt sensitive AI models.'],
risks: [{ risk: 'Model poisoning or privacy breach attacks (ex. Ransomware attacks on hospitals (e.g., 2021 Ireland Health Service ransomware attack) disabled access to patient records for weeks, affecting care continuity and patient safety)', mitigation: 'Periodic penetration testing and model robustness scoring.' }],
resources: ['<a href="https://www.iso.org/standard/81228.html" target="_blank">ISO/IEC 42001 Security for AI Systems</a>']
},
'legislative-reforms': {
title: 'Legislative and Regulatory Reforms',
description: 'Modernize PHIPA/PIPEDA and national healthcare regulations to address AI-specific challenges in liability, privacy, and post-deployment accountability.',
recommendations: ['Create risk-tiered AI regulatory pathways.', 'Mandate dynamic consent and lifecycle compliance checks.', 'Update data protection laws to account for continuously learning systems.'],
risks: [{ risk: 'Static regulations failing against dynamic AI risks (ex. The Theranos scandal highlighted how regulatory gaps around laboratory-developed testing technologies (and their software AI overlays) created public health risks)', mitigation: 'Laws requiring periodic AI policy re-evaluation tied to technical developments.' }],
resources: ['<a href="https://www.canada.ca/en/health-canada/services/health-canada-modernization/artificial-intelligence.html" target="_blank">Health Canada AI Policy Strategy</a>']
},
'system-supports': {
title: 'System Implementation Supports',
description: 'Establish governance councils, AI health sandboxes, and open-source toolkits to operationalize safe and ethical AI healthcare innovation.',
recommendations: ['Fund national AI health sandboxes for real-world testing.', 'Support Health Canada and CIHR advisory groups.', 'Distribute open-source risk audit and consent management tools.'],
risks: [{ risk: 'Fragmented, inconsistent local AI governance across regions (Early national rollouts of AI-based COVID triage chatbots in Europe (without common standards) created wildly variable risk stratifications and confusion for public health authorities)', mitigation: 'Pan-Canadian governance council establishment and toolkit sharing.' }],
resources: ['<a href="https://cihr-irsc.gc.ca/e/193.html" target="_blank">CIHR AI Health Initiatives</a>']
}
};
return content[id];
}

function getButtonLabel(id) {
const labelMap = {
'problem-definition': 'Problem Definition',
'data-collection': 'Data Collection',
'model-development': 'Model Development',
'deployment-integration': 'Deployment & Integration',
'monitoring-updating': 'Monitoring & Updating',
'decommissioning': 'Decommissioning',
'data-ownership': 'Data Ownership & Stewardship',
'liability': 'Liability & Accountability',
'privacy-consent': 'Patient Privacy & Consent',
'cybersecurity-resilience': 'Cybersecurity & Resilience',
'legislative-reforms': 'Legislative and Regulatory Reforms',
'system-supports': 'System Implementation Supports'
};
return labelMap[id];
}

function showContent(id) {
const contentBox = document.getElementById('content-box');
const content = getContent(id);

// Reset
const allItems = document.querySelectorAll('.framework-item');
allItems.forEach(item => {
item.classList.remove('active');
const arrow = item.querySelector('.arrow');
if (arrow) arrow.remove();
});

// Highlight clicked
const clickedItem = Array.from(allItems).find(item => item.innerText.trim() === getButtonLabel(id));
if (clickedItem) {
clickedItem.classList.add('active');
let arrow = document.createElement('span');
arrow.classList.add('arrow');
arrow.innerHTML = '➔';
clickedItem.appendChild(arrow);
}

// Show content
if (content) {
contentBox.innerHTML = `
<h3>${content.title}</h3>
<div class="content-grid">
<div><h4>Description</h4><p>${content.description}</p></div>
<div><h4>Recommendations</h4><ul>${content.recommendations.map(rec => `<li>${rec}</li>`).join('')}</ul></div>
<div><h4>Risks & Mitigations</h4>${content.risks.map(risk => `<div><p><strong>Risk:</strong> ${risk.risk}</p><p><strong>Mitigation:</strong> ${risk.mitigation}</p></div>`).join('')}</div>
<div><h4>Resources</h4>${content.resources.map(resource => `<p>${resource}</p>`).join('')}</div>
</div>
`;
contentBox.classList.add('active');
}
}
</script>
